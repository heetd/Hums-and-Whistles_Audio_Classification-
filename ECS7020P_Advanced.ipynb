{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o38VQkcdKd6k"
   },
   "source": [
    "# 1) Problem formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Under Supervised Learning, we have so far only looked at Multi-class classification, i.e out of `n` labels each instance is only assigned to one of the labels at a time.\n",
    "\n",
    "* Now, in advanced part we look at Multitarget classification i.e each instance can be assigned to multiples targets at a time.\n",
    "\n",
    "* Using the MLEnd Hums and Whistles dataset,we will build a machine learning pipeline that takes as an input a `Potter`, `Frozen` or `Showman` audio segment and predicts its song label (either Potter, Frozen or Showman) which is one of the target attribute and its genre(Sountrack,Show Tune or Pop) which is another target attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3BwrtEdLDit"
   },
   "source": [
    "# 2) Machine Learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The ML pipeline consists of following stages:\n",
    "\n",
    "1) The input are the 5 features that are extrated by the function `getXy` from each of the audio files and output is a model trained on the training set which is then used to evaluate the performance of the validation set.\n",
    "\n",
    "2) The features that are inserted in the pipeline are scaled by the class `StandardScalar`. The class `StandardScalar` is fitted to the features in the training set and then it normalises those features. When the pipeline is then used again to predict the labels for validation or test dataset the fitted transformer is used to transform the features in the validation or test dataset.\n",
    "\n",
    "3) Finally, the model specified in the pipeline is then fitted to the training dataset and the same model is then used to predict the lables for validation or test dataset and to evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1nDXnzYLLH6"
   },
   "source": [
    "# 3) Transformation stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The input were the audio samples and from each audio sample,using the function \"getXy\", we extracted the following features(output):\n",
    "\n",
    "1) Power <br>\n",
    "2) Pitch-mean <br>\n",
    "3) Pitch-std <br>\n",
    "4) Voiced_fr <br>\n",
    "5) Tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0F5_kI95LuZ2"
   },
   "source": [
    "# 4) Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following models will be implemented:<br>\n",
    "1) Logistic Regression Classifier<br>\n",
    "2) K-Nearest Neighbour(KNN)<br>\n",
    "3) Support Vector Machine(SVM) <br>\n",
    "4) Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPTSuaB9L2jU"
   },
   "source": [
    "# 5) Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this problem, we decided to only use files whose file name is in the correct format, so by using regex expressions we obtained  a dataset of audio segments whose file names are in the correct format and then we shuffle it to avoid the situation where after the split any of the set(train or test) contains samples of one class more. We then used the function \"getXy\" to obtain a NumPy array containing the 5 audio features used as predictors (X) and values of our target attributes i.e `y1`(song label) and `y2`(genre label). Under the target attribute `y1`(song),`y1=0` if the song is Potter, `y1=1` if the song is Frozen and `y1=2` if the song is Showman. Similarly, under the target attribute `y2`(genre),`y2=0` if the genre is `Soundtrack`, `y2=1` if the genre is `Show Tune` and `y2=2` if the genre is `Pop`. We then created datafram `df` consisting of 5 columns of features and 2 columns of the target attributes,`y1` and `y2`.\n",
    "\n",
    "\n",
    "* After that, we will split the dataframe `df` into two sets called `train` and `test` using the module `train_test_split` from sklearn library, so `X_test` set now contain 20% of the instances in the original dataframe `df`. We will then further split the `train` into `X_train` and `y_train`. Similarly, we will split `test` into `X_test` and `y_test`.\n",
    "\n",
    "\n",
    "* We will then perform K-Fold validation on the training set `train` by defining the function `cross_validation_accuracy` which will give us the mean training accuracy and mean validation accuracy. By assesing the mean validation accuracy of each different models we will choose the model that gives us the highest mean validation accuracy.\n",
    "\n",
    "\n",
    "*  After selecting the best classifier, we will train our chosen model on `train` set and test it on `test`set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZQPxztuL9AW"
   },
   "source": [
    "# 6) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys, re, pickle, glob\n",
    "#import urllib.request\n",
    "#import zipfile\n",
    "\n",
    "#import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "import librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directory_to_extract_to = r'C:\\Users\\HEET\\Desktop\\Principles of Machine Learning\\Project\\Potter\\sample'\n",
    "# zip_path = r'C:\\Users\\HEET\\Desktop\\Principles of Machine Learning\\Project\\Potter\\Potter_1.zip'\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(directory_to_extract_to)\n",
    "\n",
    "sample_path = r'C:\\Users\\HEET\\Desktop\\Principles of Machine Learning\\Project\\Potter\\sample\\*.wav'\n",
    "Potter_files = glob.glob(sample_path)\n",
    "\n",
    "# Here we are using regular expressions to find those files which are in correct format\n",
    "# After finding the file which is in correct format \n",
    "# we append it to the empty list Potter_correct_format_files and Potter_correct_format\n",
    "import re\n",
    "Potter_correct_format_files =[]\n",
    "Potter_correct_format=[]\n",
    "for file in Potter_files:\n",
    "    a = file.split('\\\\')[-1]\n",
    "    x = re.search(r\"^[S](.|..|...)_[a-zA-Z](..|......)_\\d_[P]......(wav|Wav|WAV)\",a)\n",
    "    if x is not None:\n",
    "        Potter_correct_format.append(x.string)\n",
    "        Potter_correct_format_files.append(file)\n",
    "        \n",
    "len(Potter_correct_format_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directory_to_extract_to = r'C:\\Users\\HEET\\Desktop\\Principles of Machine Learning\\Project\\Frozen\\sample'\n",
    "# zip_path = r'C:\\Users\\HEET\\Desktop\\Principles of Machine Learning\\Project\\Frozen\\Frozen_1.zip'\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(directory_to_extract_to)\n",
    "\n",
    "sample_path = r'C:\\Users\\HEET\\Desktop\\Principles of Machine Learning\\Project\\Frozen\\sample\\*.wav'\n",
    "Frozen_files = glob.glob(sample_path)\n",
    "\n",
    "import re\n",
    "Frozen_correct_format_files=[]\n",
    "Frozen_correct_format=[]\n",
    "for file in Frozen_files:\n",
    "    a = file.split('\\\\')[-1]\n",
    "    x = re.search(r\"^[S](.|..|...)_[a-zA-Z](..|......)_\\d_[F]......(wav|Wav|WAV)\",a)\n",
    "    if x is not None:\n",
    "        Frozen_correct_format.append(x.string)\n",
    "        Frozen_correct_format_files.append(file)\n",
    "        \n",
    "len(Frozen_correct_format_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directory_to_extract_to = r'C:\\Users\\HEET\\Desktop\\Principles of Machine Learning\\Project\\Showman\\sample'\n",
    "# zip_path = r'C:\\Users\\HEET\\Desktop\\Principles of Machine Learning\\Project\\Showman\\Showman_1.zip'\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(directory_to_extract_to)\n",
    "\n",
    "sample_path = r'C:\\Users\\HEET\\Desktop\\Principles of Machine Learning\\Project\\Showman\\sample\\*.wav'\n",
    "Showman_files = glob.glob(sample_path)\n",
    "\n",
    "import re\n",
    "Showman_correct_format_files=[]\n",
    "Showman_correct_format=[]\n",
    "for file in Showman_files:\n",
    "    a = file.split('\\\\')[-1]\n",
    "    x = re.search(r\"^[S](.|..|...)_[a-zA-Z](..|......)_\\d_[S].......(wav|Wav|WAV)\",a)\n",
    "    if x is not None:\n",
    "        Showman_correct_format.append(x.string)\n",
    "        Showman_correct_format_files.append(file)        \n",
    "        \n",
    "len(Showman_correct_format_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>interpretation</th>\n",
       "      <th>number</th>\n",
       "      <th>song</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S100_hum_1_Potter.wav</th>\n",
       "      <td>S100</td>\n",
       "      <td>hum</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Soundtrack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S100_hum_2_Potter.wav</th>\n",
       "      <td>S100</td>\n",
       "      <td>hum</td>\n",
       "      <td>2</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Soundtrack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S101_hum_1_Potter.wav</th>\n",
       "      <td>S101</td>\n",
       "      <td>hum</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Soundtrack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S101_hum_2_Potter.wav</th>\n",
       "      <td>S101</td>\n",
       "      <td>hum</td>\n",
       "      <td>2</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Soundtrack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S102_hum_2_Potter.wav</th>\n",
       "      <td>S102</td>\n",
       "      <td>hum</td>\n",
       "      <td>2</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Soundtrack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S94_whistle_2_Showman.wav</th>\n",
       "      <td>S94</td>\n",
       "      <td>whistle</td>\n",
       "      <td>2</td>\n",
       "      <td>Showman</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S97_hum_3_Showman.wav</th>\n",
       "      <td>S97</td>\n",
       "      <td>hum</td>\n",
       "      <td>3</td>\n",
       "      <td>Showman</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S97_hum_4_Showman.wav</th>\n",
       "      <td>S97</td>\n",
       "      <td>hum</td>\n",
       "      <td>4</td>\n",
       "      <td>Showman</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S9_hum_3_Showman.wav</th>\n",
       "      <td>S9</td>\n",
       "      <td>hum</td>\n",
       "      <td>3</td>\n",
       "      <td>Showman</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S9_hum_4_Showman.wav</th>\n",
       "      <td>S9</td>\n",
       "      <td>hum</td>\n",
       "      <td>4</td>\n",
       "      <td>Showman</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          participant interpretation number     song  \\\n",
       "file_id                                                                \n",
       "S100_hum_1_Potter.wav            S100            hum      1   Potter   \n",
       "S100_hum_2_Potter.wav            S100            hum      2   Potter   \n",
       "S101_hum_1_Potter.wav            S101            hum      1   Potter   \n",
       "S101_hum_2_Potter.wav            S101            hum      2   Potter   \n",
       "S102_hum_2_Potter.wav            S102            hum      2   Potter   \n",
       "...                               ...            ...    ...      ...   \n",
       "S94_whistle_2_Showman.wav         S94        whistle      2  Showman   \n",
       "S97_hum_3_Showman.wav             S97            hum      3  Showman   \n",
       "S97_hum_4_Showman.wav             S97            hum      4  Showman   \n",
       "S9_hum_3_Showman.wav               S9            hum      3  Showman   \n",
       "S9_hum_4_Showman.wav               S9            hum      4  Showman   \n",
       "\n",
       "                                genre  \n",
       "file_id                                \n",
       "S100_hum_1_Potter.wav      Soundtrack  \n",
       "S100_hum_2_Potter.wav      Soundtrack  \n",
       "S101_hum_1_Potter.wav      Soundtrack  \n",
       "S101_hum_2_Potter.wav      Soundtrack  \n",
       "S102_hum_2_Potter.wav      Soundtrack  \n",
       "...                               ...  \n",
       "S94_whistle_2_Showman.wav         Pop  \n",
       "S97_hum_3_Showman.wav             Pop  \n",
       "S97_hum_4_Showman.wav             Pop  \n",
       "S9_hum_3_Showman.wav              Pop  \n",
       "S9_hum_4_Showman.wav              Pop  \n",
       "\n",
       "[497 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLENDHW_table = [] \n",
    "\n",
    "for file in Potter_correct_format:\n",
    "    file_name = file.split('\\\\')[-1]\n",
    "    participant_ID = file.split('\\\\')[-1].split('_')[0]\n",
    "    interpretation_type = file.split('\\\\')[-1].split('_')[1]\n",
    "    interpretation_number = file.split('\\\\')[-1].split('_')[2]\n",
    "    song = file.split('\\\\')[-1].split('_')[3].split('.')[0]\n",
    "    genre = \"Soundtrack\"\n",
    "    MLENDHW_table.append([file_name,participant_ID,interpretation_type,interpretation_number, song, genre])\n",
    "\n",
    "for file in Frozen_correct_format:\n",
    "    file_name = file.split('\\\\')[-1]\n",
    "    participant_ID = file.split('\\\\')[-1].split('_')[0]\n",
    "    interpretation_type = file.split('\\\\')[-1].split('_')[1]\n",
    "    interpretation_number = file.split('\\\\')[-1].split('_')[2]\n",
    "    song = file.split('\\\\')[-1].split('_')[3].split('.')[0]\n",
    "    genre = \"Show Tune\"\n",
    "    MLENDHW_table.append([file_name,participant_ID,interpretation_type,interpretation_number, song, genre])\n",
    "    \n",
    "for file in Showman_correct_format:\n",
    "    file_name = file.split('\\\\')[-1]\n",
    "    participant_ID = file.split('\\\\')[-1].split('_')[0]\n",
    "    interpretation_type = file.split('\\\\')[-1].split('_')[1]\n",
    "    interpretation_number = file.split('\\\\')[-1].split('_')[2]\n",
    "    song = file.split('\\\\')[-1].split('_')[3].split('.')[0]\n",
    "    genre = \"Pop\"\n",
    "    MLENDHW_table.append([file_name,participant_ID,interpretation_type,interpretation_number, song, genre])\n",
    "\n",
    "\n",
    "\n",
    "MLENDHW_df = pd.DataFrame(MLENDHW_table,columns=['file_id','participant','interpretation','number','song','genre']).set_index('file_id') \n",
    "\n",
    "# a datafram where the file_id is in correct format\n",
    "MLENDHW_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "files = Potter_correct_format_files + Frozen_correct_format_files + Showman_correct_format_files\n",
    "\n",
    "# We shuffled files to avoid the situation where after the split any of the set contains samples of either labels more\n",
    "files = shuffle(files,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPitch(x,fs,winLen=0.02):\n",
    "  #winLen = 0.02 \n",
    "  p = winLen*fs\n",
    "  frame_length = int(2**int(p-1).bit_length())\n",
    "  hop_length = frame_length//2\n",
    "  f0, voiced_flag, voiced_probs = librosa.pyin(y=x, fmin=80, fmax=450, sr=fs,\n",
    "                                                 frame_length=frame_length,hop_length=hop_length)\n",
    "  return f0,voiced_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXy(files,labels_file, scale_audio=False, onlySingleDigit=False):\n",
    "  X,y1,y2 =[],[],[]\n",
    "  for file in tqdm(files):\n",
    "    fileID = file.split('\\\\')[-1]\n",
    "    file_name = file.split('\\\\')[-1]\n",
    "    \n",
    "    if labels_file.loc[fileID]['song']=='Potter':\n",
    "        y_1 = 0\n",
    "    if labels_file.loc[fileID]['genre']=='Soundtrack':\n",
    "        y_2 = \"0\"\n",
    "    if labels_file.loc[fileID]['song']=='Frozen':\n",
    "        y_1 = \"1\"\n",
    "    if labels_file.loc[fileID]['genre']=='Show Tune':\n",
    "        y_2 = \"1\"\n",
    "    if labels_file.loc[fileID]['song']=='Showman':\n",
    "        y_1 = \"2\"\n",
    "    if labels_file.loc[fileID]['genre']=='Pop':\n",
    "        y_2 = \"2\"    \n",
    "\n",
    "    fs = None # if None, fs would be 22050\n",
    "    x, fs = librosa.load(file,sr=fs)\n",
    "    if scale_audio: x = x/np.max(np.abs(x))\n",
    "    f0, voiced_flag = getPitch(x,fs,winLen=0.02)\n",
    "      \n",
    "    power = np.sum(x**2)/len(x)\n",
    "    pitch_mean = np.nanmean(f0) if np.mean(np.isnan(f0))<1 else 0\n",
    "    pitch_std  = np.nanstd(f0) if np.mean(np.isnan(f0))<1 else 0\n",
    "    voiced_fr = np.mean(voiced_flag)\n",
    "    tempo = (librosa.beat.tempo(x, sr=fs))[0]\n",
    "\n",
    "    xi = [power,pitch_mean,pitch_std,voiced_fr,tempo]\n",
    "    X.append(xi)\n",
    "    y1.append(y_1)\n",
    "    y2.append(y_2)\n",
    "\n",
    "  return np.array(X),np.array(y1),np.array(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After running the above code, we obtained 3 numpy arrays `X`,`y1` and `y2` which I stored as `X_advanced` and `y1` and `y2`.\n",
    "* I have loaded them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"X_advanced.npy\")\n",
    "y1 = np.load(\"y1.npy\")\n",
    "y2 = np.load(\"y2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Power</th>\n",
       "      <th>Pitch_mean</th>\n",
       "      <th>Pitch_std</th>\n",
       "      <th>Voiced_fr</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>187.109414</td>\n",
       "      <td>48.174835</td>\n",
       "      <td>0.801676</td>\n",
       "      <td>123.046875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037909</td>\n",
       "      <td>282.691676</td>\n",
       "      <td>45.326666</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>132.512019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069781</td>\n",
       "      <td>208.004928</td>\n",
       "      <td>39.000433</td>\n",
       "      <td>0.695428</td>\n",
       "      <td>132.512019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044952</td>\n",
       "      <td>188.459884</td>\n",
       "      <td>27.973096</td>\n",
       "      <td>0.798455</td>\n",
       "      <td>166.708669</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018885</td>\n",
       "      <td>165.580954</td>\n",
       "      <td>23.057535</td>\n",
       "      <td>0.809588</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.065192</td>\n",
       "      <td>379.606907</td>\n",
       "      <td>45.292738</td>\n",
       "      <td>0.621200</td>\n",
       "      <td>126.048018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.053954</td>\n",
       "      <td>409.766027</td>\n",
       "      <td>26.274146</td>\n",
       "      <td>0.817330</td>\n",
       "      <td>139.674831</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.048838</td>\n",
       "      <td>138.307890</td>\n",
       "      <td>36.794285</td>\n",
       "      <td>0.821128</td>\n",
       "      <td>132.512019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.006714</td>\n",
       "      <td>312.389485</td>\n",
       "      <td>50.907812</td>\n",
       "      <td>0.613213</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.035155</td>\n",
       "      <td>396.742737</td>\n",
       "      <td>26.588833</td>\n",
       "      <td>0.749869</td>\n",
       "      <td>143.554688</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Power  Pitch_mean  Pitch_std  Voiced_fr       Tempo y1 y2\n",
       "0    0.034483  187.109414  48.174835   0.801676  123.046875  0  0\n",
       "1    0.037909  282.691676  45.326666   0.791667  132.512019  1  1\n",
       "2    0.069781  208.004928  39.000433   0.695428  132.512019  1  1\n",
       "3    0.044952  188.459884  27.973096   0.798455  166.708669  2  2\n",
       "4    0.018885  165.580954  23.057535   0.809588  112.347147  2  2\n",
       "..        ...         ...        ...        ...         ... .. ..\n",
       "492  0.065192  379.606907  45.292738   0.621200  126.048018  1  1\n",
       "493  0.053954  409.766027  26.274146   0.817330  139.674831  1  1\n",
       "494  0.048838  138.307890  36.794285   0.821128  132.512019  0  0\n",
       "495  0.006714  312.389485  50.907812   0.613213  112.500000  0  0\n",
       "496  0.035155  396.742737  26.588833   0.749869  143.554688  1  1\n",
       "\n",
       "[497 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X,columns = [\"Power\",\"Pitch_mean\",\"Pitch_std\",\"Voiced_fr\",\"Tempo\"])\n",
    "df[\"y1\"] = y1\n",
    "df[\"y2\"] = y2\n",
    "df[\"y1\"] = df[\"y1\"].astype(\"category\")\n",
    "df[\"y2\"] = df[\"y2\"].astype(\"category\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the above dataframe, under `y1`, the label `0`  corresponds to the song `Potter`, label `1` corresponds to the song `Frozen` and label `2` corresponnds to song `Showman`. Similarly under `y2` the label `0`  corresponds to the genre `Soundtrack`, label `1` corresponds to the genre `Show Tune` and label `2` corresponnds to genre `Pop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Power</th>\n",
       "      <th>Pitch_mean</th>\n",
       "      <th>Pitch_std</th>\n",
       "      <th>Voiced_fr</th>\n",
       "      <th>Tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.038745</td>\n",
       "      <td>268.063734</td>\n",
       "      <td>40.371996</td>\n",
       "      <td>0.751324</td>\n",
       "      <td>127.682924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.030188</td>\n",
       "      <td>99.324571</td>\n",
       "      <td>16.764239</td>\n",
       "      <td>0.117189</td>\n",
       "      <td>18.121737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001254</td>\n",
       "      <td>98.481530</td>\n",
       "      <td>9.823539</td>\n",
       "      <td>0.185645</td>\n",
       "      <td>90.666118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.020171</td>\n",
       "      <td>175.896162</td>\n",
       "      <td>28.833734</td>\n",
       "      <td>0.690784</td>\n",
       "      <td>117.453835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.030166</td>\n",
       "      <td>244.998040</td>\n",
       "      <td>35.243253</td>\n",
       "      <td>0.767737</td>\n",
       "      <td>126.048018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.047424</td>\n",
       "      <td>370.729465</td>\n",
       "      <td>50.177960</td>\n",
       "      <td>0.833448</td>\n",
       "      <td>135.999178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.257340</td>\n",
       "      <td>431.863787</td>\n",
       "      <td>124.472669</td>\n",
       "      <td>0.967474</td>\n",
       "      <td>198.768029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Power  Pitch_mean   Pitch_std   Voiced_fr       Tempo\n",
       "count  497.000000  497.000000  497.000000  497.000000  497.000000\n",
       "mean     0.038745  268.063734   40.371996    0.751324  127.682924\n",
       "std      0.030188   99.324571   16.764239    0.117189   18.121737\n",
       "min      0.001254   98.481530    9.823539    0.185645   90.666118\n",
       "25%      0.020171  175.896162   28.833734    0.690784  117.453835\n",
       "50%      0.030166  244.998040   35.243253    0.767737  126.048018\n",
       "75%      0.047424  370.729465   50.177960    0.833448  135.999178\n",
       "max      0.257340  431.863787  124.472669    0.967474  198.768029"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looking at the above statistics of each feature we can see that max value of `Power` and `Voiced_fr` doesnot even exceeds 1 whereas the max value of `Pitch_std` and `Tempo` exceeds 100 and so we need to normalise the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will use the `df` to obtain training(`train`) and test(`test`) set.\n",
    "\n",
    "* We will then further split the `train` into `X_train` and `y_train`. Similarly, we will split `test` into `X_test` and `y_test`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((347, 7), (150, 7))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we will obtain training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,test = train_test_split(df, test_size=0.3, random_state=0)# test_size is 20% of data size\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We further split the training set into training set of predictors(X) and labels(y1 and y2)\n",
    "X_train = train.iloc[: , :5]\n",
    "y_train = train.iloc[:  , 5:]\n",
    "\n",
    "# We further split the test set into testing set of predictors(X) and labels(y1 and y2)\n",
    "X_test = test.iloc[: , :5]\n",
    "y_test = test.iloc[: , 5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will now perform K-fold cross validation on the training set by using the function the `cross_validation_accuracy` which will give us mean training and validation accuracy for each different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_accuracy(classifier):\n",
    "    training_accuracy = []\n",
    "    validation_accuracy = []\n",
    "    \n",
    "    # Here we have the Pipeline\n",
    "    pipe = Pipeline([(\"scaler\",StandardScaler()),\n",
    "                     (\"classifier\",classifier)\n",
    "                    ])\n",
    "    print(\"The steps of the Pipe are:\\n\" ,pipe.steps,\"\\n\")\n",
    "    \n",
    "    kf = KFold(n_splits = 10)\n",
    "    \n",
    "    # kf.split(X_train) will give us training indices and validation indices\n",
    "    # we will use this indices to obtain the training set and validation from \"train\" set\n",
    "    for train_index, val_index in kf.split(train):\n",
    "        X_t, y_t = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_v, y_v = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "        \n",
    "        pipe.fit(X_t,y_t)\n",
    "        yt_predict = pipe.predict(X_t)\n",
    "        yv_predict = pipe.predict(X_v)\n",
    "        \n",
    "        # we are adding the training accuracy of each fold to the empty list training_accuracy\n",
    "        training_accuracy.append(pipe.score(X_t , y_t))\n",
    "        \n",
    "        # we are adding the validation accuracy of each fold to the empty list validation_accuracy\n",
    "        validation_accuracy.append(pipe.score(X_v, y_v))\n",
    "        \n",
    "        \n",
    "    print(\"Mean Training Accuracy: \", np.mean(training_accuracy))\n",
    "    print(\"Mean Validation Accuracy: \", np.mean(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qf7GN1aeXJI"
   },
   "source": [
    "# 7) Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using MultiOutputClassifier we fit one classifier to each of the target attributes. Through this we can fit classifiers that do not originally support multi-target classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i) Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The steps of the Pipe are:\n",
      " [('scaler', StandardScaler()), ('classifier', MultiOutputClassifier(estimator=LogisticRegression()))] \n",
      "\n",
      "Mean Training Accuracy:  0.47325305152781194\n",
      "Mean Validation Accuracy:  0.46042016806722685\n"
     ]
    }
   ],
   "source": [
    "cross_validation_accuracy(MultiOutputClassifier(LogisticRegression()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We performed cross-validation using the `train` set and then fittied Logistic Regression Classifier to the training set obtained from `train` set and, then obtained training and validation accuracy for each fold.\n",
    "\n",
    "* We obtained mean training accuracy of 47.33% and mean validation accuracy of 46.04% which is very poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii) K-Nearest Neighbor(KNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The steps of the Pipe are:\n",
      " [('scaler', StandardScaler()), ('classifier', MultiOutputClassifier(estimator=KNeighborsClassifier(n_neighbors=7)))] \n",
      "\n",
      "Mean Training Accuracy:  0.6778600393217008\n",
      "Mean Validation Accuracy:  0.5818487394957982\n"
     ]
    }
   ],
   "source": [
    "cross_validation_accuracy(MultiOutputClassifier(KNeighborsClassifier(7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We performed cross-validation using the `train` set and then fittied KNN classifier to the training set obtained from `train` set and, then obtained training and validation accuracy for each fold.\n",
    "\n",
    "* We obtained mean training accuracy of 67.79% and mean validation accuracy of 58.18% which is poor but in terms of mean validation accuracy it is better than Logistic Regression Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii) Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The steps of the Pipe are:\n",
      " [('scaler', StandardScaler()), ('classifier', MultiOutputClassifier(estimator=SVC(C=1)))] \n",
      "\n",
      "Mean Training Accuracy:  0.6887544032112722\n",
      "Mean Validation Accuracy:  0.5931932773109243\n"
     ]
    }
   ],
   "source": [
    "model  = svm.SVC(C=1)\n",
    "cross_validation_accuracy(MultiOutputClassifier(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We performed cross-validation using the `train` set and then fittied Support Vector Machine model to the training set obtained from `train` set and, then obtained training and validation accuracy for each fold.\n",
    "\n",
    "* We obtained mean training accuracy of 68.88% and mean validation accuracy of 59.32% which is poor but in terms of mean validation accuracy it is better than Logistic Regression Classifier and KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iv) Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The steps of the Pipe are:\n",
      " [('scaler', StandardScaler()), ('classifier', MultiOutputClassifier(estimator=RandomForestClassifier(n_estimators=150,\n",
      "                                                       random_state=0)))] \n",
      "\n",
      "Mean Training Accuracy:  1.0\n",
      "Mean Validation Accuracy:  0.6076470588235294\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=150,max_features=\"auto\",random_state=0)\n",
    "cross_validation_accuracy(MultiOutputClassifier(RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We performed cross-validation using the `train` set and then fittied Random Forest Classifier to the training set obtained from `train` set and, then obtained training and validation accuracy for each fold.\n",
    "\n",
    "* We obtained mean training accuracy of 100% and mean validation accuracy of 60.76% which is still quite poor but in terms of mean validation accuracy it is better than all of the models that we have considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we will train the RandomForestClassifier on training set `train` and test it on the testing set `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=150,max_features=\"auto\",random_state=0)\n",
    "pipe = Pipeline([(\"scaler\",StandardScaler()),\n",
    "                     (\"classifier\",MultiOutputClassifier(RFC))\n",
    "                    ])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "print(\"Test Accuracy:\",pipe.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSrJCR_cekPO"
   },
   "source": [
    "# 8) Conclusions\n",
    "\n",
    "Your conclusions, improvements, etc should go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We evaluated 4 classifiers which are `Logistic Regression classifier`, `K-Nearest Neighbour(KNN) classifier`,`Suport Vector Machine` and `Random Forest classifier`. We performed 10-fold cross validation on training set `train` and then fitted all these model on training set under each fold and obtained validation accuracy for each fold. Using `cross_validation_accuracy` we obtained mean training and validation accuracy for each of these models. Random Forest Classifier gave the highest mean validation accuracy.\n",
    "\n",
    "* After that, we trained the Random Forest classifier on the 5 features that were extracted from the 80% of the original sample i.e 347 audio samples and finally tested the model on the test dataset which consisted of 5 features extracted from 150 audio samples, giving the `test accuracy` of `53.33% ` which is poor.\n",
    "\n",
    "* One of the reason for such low accuracies can be that the 5 features are not enough in predicting the song and its genre. So we can improve the accuracies by adding more features such as `Zero Crossing Rate` and `Mel-Frequency Cepstral Coefficients(MFCC)`. We should also inspect whether there is correlation between the features and if there is we should perform Principal Component Analysis(PCA).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ECS7020P_miniproject_submission.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
